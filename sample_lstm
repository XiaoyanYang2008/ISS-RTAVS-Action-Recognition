#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import pandas as pd
import tensorflow as tf
import numpy as np
import sys
import os
from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten,LSTM,Input,Conv1D,MaxPooling1D
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.preprocessing import OneHotEncoder

classes = {'raisehandsSwitch':0,
           'righthandclick':1,
           'righthandNext':2,
          'shutdown':3}

t = [a*3-1 for a in range(1,20)]

def read_data():
    """
        Takes the list of .csv files, containing the 19 joint positions and creates the keypoints dataframe
        and labels. For this LSTM model, only the (x,y) locations of each joint are taken.
        
        The shape of the final dataframe is in the form of (samples,timesteps,features)
        where
        - sample = No of training videos e.g. 12
        - timesteps = No. of frames in each video (padding added to fit the longest video)
        - features = No. of joint (x,y) coordinates e.g. 19 joints * 2 coordinates = 38
        
        *Returns*: A tuple of the final joint coordinate dataframe and the video labels
    
    """ 
    flist = os.listdir('./data/training-csv/')
    df = []
    y = []
    for file in flist:
        temp2 = pd.read_csv('./data/training-csv/'+file,header=None)
#        print(temp.shape)
        temp = np.delete(np.array(temp2),t,axis=1)
        temp = temp.flatten()
        temp = np.pad(temp,(0,120*38-len(temp)),mode='constant',constant_values=0)
#        temp = pad_sequences(temp,maxlen=100*57,padding='post')
        temp = temp.reshape(120,38)
#        print(temp.shape)
        df.append(temp)
        
        label = file.split('_')[0]
        y.append(classes[label])
        
    df2 = np.stack(df,axis=0)
    y2 = to_categorical(y)
    return (df2,y2)
        
train_x,train_y = read_data()

def createModel():
    """
        Creates a LSTM model with convolutional layers at the start. 
        
        The input shape is given as (timesteps,features) as explained in read_data(). The model is currently set to use
        batch size=1 i.e. SGD type but cna be modified for mini-batch training. 
        
        
    """   
    x= Input(shape=(120,38))
    out = Conv1D(16,3,activation='relu',padding='same')(x)
    out = MaxPooling1D(2)(out)
    out = Conv1D(32,3,activation='relu',padding='same')(out)
    out = MaxPooling1D(2)(out)
    out = LSTM(64,return_sequences=True)(out)
    out = LSTM(32,return_sequences=True)(out)
    out = LSTM(16)(out)
    out = Dense(4,activation='softmax')(out)
    model = Model(x,out)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])
    return model

modelname = 'action_lstm'
model = createModel()
model.summary()


filepath        = modelname + ".hdf5"
checkpoint      = ModelCheckpoint(filepath, 
                                  monitor='val_acc', 
                                  verbose=0, 
                                  save_best_only=True, 
                                  mode='max')

                            # Log the epoch detail into csv
csv_logger      = CSVLogger(modelname +'.csv')
callbacks_list  = [checkpoint,csv_logger]

model.fit(train_x,train_y,epochs=50,callbacks=callbacks_list)
